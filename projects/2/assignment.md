# Section 2: Decision Trees II

## Exercise 2.1: Decision Tree from Scratch

**Objective:**  
Implement a Decision Tree classifier from scratch without using any machine learning library. Use Python and NumPy to handle the dataset.

**Instructions:**
1. Implement the ID3 or CART algorithm for building decision trees.
2. Choose a classification dataset (e.g., Titanic or a custom dataset).
3. Implement functions for calculating Gini impurity or information gain, selecting features, and splitting nodes.
4. Train the decision tree and evaluate its performance using appropriate metrics.

**Deliverables:**
- Python code implementing the ID3 or CART algorithm.
- A report or output showing the trained decision tree and evaluation metrics (accuracy, precision, recall).
- A plot of the decision tree, if possible.
